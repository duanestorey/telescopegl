# -*- coding: utf-8 -*-
"""TelescopeLikelihood â€” EM algorithm for resolving multi-mapped reads.

This module contains the core EM algorithm used by Telescope to assign
ambiguous RNA-seq fragments to transposable element loci.
"""
import logging as lg
from time import perf_counter

import numpy as np

from .sparse_plus import csr_matrix_plus as csr_matrix

__author__ = 'Matthew L. Bendall'
__copyright__ = "Copyright (C) 2019 Matthew L. Bendall"


class TelescopeLikelihood(object):
    """EM algorithm for resolving multi-mapped fragment assignments.

    Given a sparse score matrix Q[i,j] (N fragments x K transcripts),
    iteratively estimates:
      - pi[j]: proportion of fragments from transcript j
      - theta[j]: proportion of ambiguous fragments assigned to transcript j
      - z[i,j]: posterior probability of fragment i originating from transcript j
    """

    def __init__(self, score_matrix, opts):
        # Raw scores
        self.raw_scores = score_matrix
        self.max_score = self.raw_scores.max()

        # N fragments x K transcripts
        self.N, self.K = self.raw_scores.shape

        # Q[i,] is the set of mapping qualities for fragment i, where Q[i,j]
        # represents the evidence for fragment i being generated by fragment j.
        # Scale the raw alignment score by the maximum alignment score
        # and multiply by a scale factor.
        self.scale_factor = 100.
        self.Q = self.raw_scores.scale().multiply(self.scale_factor).expm1()

        # z[i,] is the partial assignment weights for fragment i
        self.z = None

        self.epsilon = opts.em_epsilon
        self.max_iter = opts.max_iter

        # pi[j] is the proportion of fragments that originate from
        # transcript j. Initial value assumes equal proportions.
        self.pi = np.repeat(1./self.K, self.K)
        self.pi_init = None

        # theta[j] is the proportion of non-unique fragments reassigned
        # to transcript j. Initial value assumes equal proportions.
        self.theta = np.repeat(1./self.K, self.K)
        self.theta_init = None

        # Y[i] is the ambiguity indicator: Y[i]=1 if fragment i maps
        # to multiple transcripts, 0 otherwise. Store as N x 1 matrix.
        self.Y = (self.Q.count(1) > 1).astype(np.uint8)
        self._yslice = self.Y[:,0].nonzero()[0]

        # Log-likelihood score
        self.lnl = float('inf')

        # Prior values
        self.pi_prior = opts.pi_prior
        self.theta_prior = opts.theta_prior

        # Precalculated values
        self._weights = self.Q.max(1)
        self._total_wt = self._weights.sum()
        self._ambig_wt = self._weights.multiply(self.Y).sum()
        self._unique_wt = self._weights.multiply(1-self.Y).sum()

        # Weighted prior values
        self._pi_prior_wt = self.pi_prior * self._weights.max()
        self._theta_prior_wt = self.theta_prior * self._weights.max()
        self._pisum0 = self.Q.multiply(1-self.Y).sum(0)
        lg.debug('done initializing model')

    def estep(self, pi, theta):
        """Calculate expected values of z.

        E(z[i,j]) = ( pi[j] * theta[j]**Y[i] * Q[i,j] ) / sum_k(...)
        """
        lg.debug('started e-step')
        _amb = csr_matrix(self.Q.multiply(self.Y)).multiply(pi * theta)
        _uni = csr_matrix(self.Q.multiply(1 - self.Y)).multiply(pi)
        _n = csr_matrix(_amb + _uni)
        return _n.norm(1)

    def mstep(self, z):
        """Calculate MAP estimates for pi and theta."""
        lg.debug('started m-step')
        _weighted = z.multiply(self._weights)

        # Estimate theta_hat
        _thetasum = _weighted.multiply(self.Y).sum(0)
        _theta_denom = self._ambig_wt + self._theta_prior_wt * self.K
        _theta_hat = (_thetasum + self._theta_prior_wt) / _theta_denom

        # Estimate pi_hat
        _pisum = self._pisum0 + _thetasum
        _pi_denom = self._total_wt + self._pi_prior_wt * self.K
        _pi_hat = (_pisum + self._pi_prior_wt) / _pi_denom

        return _pi_hat.A1, _theta_hat.A1

    def calculate_lnl(self, z, pi, theta):
        """Calculate log-likelihood."""
        lg.debug('started lnl')
        _amb = csr_matrix(self.Q.multiply(self.Y)).multiply(pi * theta)
        _uni = csr_matrix(self.Q.multiply(1 - self.Y)).multiply(pi)
        _inner = csr_matrix(_amb + _uni)
        cur = z.multiply(_inner.log1p()).sum()
        lg.debug('completed lnl')
        return cur

    def em(self, use_likelihood=False, loglev=lg.WARNING, save_memory=True):
        """Run EM algorithm until convergence or max iterations."""
        inum = 0
        converged = False
        reached_max = False

        msgD = 'Iteration {:d}, diff={:.5g}'
        msgL = 'Iteration {:d}, lnl= {:.5e}, diff={:.5g}'
        while not (converged or reached_max):
            xtime = perf_counter()
            _z = self.estep(self.pi, self.theta)
            _pi, _theta = self.mstep(_z)
            inum += 1
            if inum == 1:
                self.pi_init = _pi
                self.theta_init = _theta

            diff_est = abs(_pi - self.pi).sum()

            if use_likelihood:
                _lnl = self.calculate_lnl(_z, _pi, _theta)
                diff_lnl = abs(_lnl - self.lnl)
                lg.log(loglev, msgL.format(inum, _lnl, diff_est))
                converged = diff_lnl < self.epsilon
                self.lnl = _lnl
            else:
                lg.log(loglev, msgD.format(inum, diff_est))
                converged = diff_est < self.epsilon

            reached_max = inum >= self.max_iter
            self.z = _z
            self.pi, self.theta = _pi, _theta
            lg.debug("time: {}".format(perf_counter()-xtime))

        _con = 'converged' if converged else 'terminated'
        if not use_likelihood:
            self.lnl = self.calculate_lnl(self.z, self.pi, self.theta)

        lg.log(loglev, 'EM {:s} after {:d} iterations.'.format(_con, inum))
        lg.log(loglev, 'Final log-likelihood: {:f}.'.format(self.lnl))
        return

    def reassign(self, method, thresh=0.9, initial=False):
        """Reassign fragments to expected transcripts.

        Args:
            method: One of 'exclude', 'choose', 'average', 'conf', 'unique', 'all'
            thresh: Confidence threshold for 'conf' mode
            initial: If True, use Q.norm(1) instead of z

        Returns:
            Sparse matrix where m[i,j] == 1 iff read i is reassigned to transcript j
        """
        if method not in ['exclude', 'choose', 'average', 'conf', 'unique', 'all']:
            raise ValueError('Argument "method" should be one of (exclude, choose, average, conf, unique, all)')

        _z = self.Q.norm(1) if initial else self.z

        if method == 'exclude':
            v = _z.binmax(1)
            assignments = v.multiply(v.sum(1) == 1)
        elif method == 'choose':
            v = _z.binmax(1)
            assignments = v.choose_random(1)
        elif method == 'average':
            v = _z.binmax(1)
            assignments = v.norm(1)
        elif method == 'conf':
            v = _z.apply_func(lambda x: x if x >= thresh else 0)
            assignments = v.norm(1)
        elif method == 'unique':
            assignments = _z.multiply(1 - self.Y).ceil().astype(np.uint8)
        elif method == 'all':
            assignments = _z.apply_func(lambda x: 1 if x > 0 else 0).astype(np.uint8)

        assignments = csr_matrix(assignments)
        return assignments
